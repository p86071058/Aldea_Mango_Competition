{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"object_localization.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1wqsaitbAAiNNOPqKfUtjSG7BNKVSxLvl","authorship_tag":"ABX9TyONHyIVThFg1/Kfk7QJrl5U"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"iGnFqPoYUMUm"},"source":["import os\r\n","import cv2\r\n","import numpy as np\r\n","import pandas as pd\r\n","import tensorflow as tf\r\n","from functools import partial\r\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R6_eN6NEUffy"},"source":["csv_path = '/content/drive/My Drive/project/mango/test/'\r\n","image_path = '/content/drive/My Drive/project/mango/test/image/Test/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehTGPBGWUsT4"},"source":["def load_csv(csv_path, file_name):\r\n","    dataset = pd.read_csv(os.path.join(csv_path, file_name), low_memory = False)\r\n","    # dataset = pd.read_csv(os.path.join(csv_path, file_name), header = None, low_memory = False)\r\n","    dataset.fillna('1', inplace = True)\r\n","    dataset_array = np.array(dataset)\r\n","    return dataset, dataset_array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-iFmH8yU2jA"},"source":["dataset, dataset_array = load_csv(csv_path, 'Test_mangoXYWH.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MilQZTOvX-yQ"},"source":["# Write TFRecord Dataset"]},{"cell_type":"code","metadata":{"id":"Hyug-URlyCrh"},"source":["def _bytes_feature(value):\n","  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","  if isinstance(value, type(tf.constant(0))):\n","    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","  return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n","\n","def _float_feature(value):\n","  \"\"\"Returns a float_list from a float / double.\"\"\"\n","  return tf.train.Feature(float_list = tf.train.FloatList(value = [value]))\n","\n","\n","def _int64_feature(value):\n","  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","  return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))\n","\n","def serialize_array(array):\n","  array = tf.io.serialize_tensor(array)\n","  return array\n","\n","def segment(data):\n","    feature_set= []\n","    img_name = []\n","    demension = len(data[0])\n","    segment = list(range(1, demension, 5))\n","    for i in range(len(data)):\n","        for seg in segment:\n","            if data[i][seg] == '1':\n","                pass\n","            else:\n","                sub_data = data[i][seg:seg + 5]\n","                img = data[i][0]\n","                feature_set.append(sub_data)\n","                img_name.append(img)\n","    img_name = np.array(img_name)\n","    feature_set = np.array(feature_set)\n","    label = feature_set[:,4]\n","    w_h = feature_set[:,:4].astype('float32')\n","    return img_name, feature_set, label, w_h\n","\n","\n","def image_example(image, b_box):\n","    # image = plt.imread(os.path.join(image_path, file_name))\n","    # image_string = open(os.path.join(image_path, file_name), 'rb').read()\n","    # image_shape = tf.image.decode_jpeg(image_string).shape\n","    image_string = tf.image.encode_jpeg(image)\n","    feature = {\n","      'image_raw': _bytes_feature(image_string),\n","      'target':_bytes_feature(b_box),\n","    }\n","    return tf.train.Example(features = tf.train.Features(feature = feature))\n","\n","def image_example_2(image, cordinate):\n","    image_string = tf.image.encode_jpeg(image)\n","    feature = {\n","      'image_raw': _bytes_feature(image_string),\n","      'cordinate' : _bytes_feature(cordinate)\n","    }\n","    return tf.train.Example(features = tf.train.Features(feature = feature))\n","def y_label(label):\n","  target = np.zeros((5,4), dtype = 'float32')\n","  if label == '不良-乳汁吸附':\n","    o_h_e[0,0] = 1\n","  elif label == '不良-機械傷害':\n","    o_h_e[0,1] = 1\n","  elif label == '不良-炭疽病':\n","    o_h_e[0,2] = 1\n","  elif label == '不良-著色不佳':\n","    o_h_e[0,3] = 1\n","  else:\n","    o_h_e[0,4] = 1\n","  # return o_h_e.tostring()\n","  return o_h_e.tobytes()\n","  # return o_h_e\n","\n","def scale_bbox(cor, x_scale, y_scale):\n","  x, y, w, h = cor\n","  new_x, new_y, new_w, new_h = int(np.round(x * x_scale)), int(np.round(y * y_scale)), \\\n","                               int(np.round(w * x_scale)), int(np.round(h * y_scale))\n","  return np.array([new_x / 224, new_y / 224, new_w / 224, new_h / 224]).astype(np.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMeEg5bKnyic"},"source":["cor = dataset_array[:, 1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzpHJyyomNtu","executionInfo":{"status":"ok","timestamp":1609599861163,"user_tz":-480,"elapsed":830,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"383f1868-2311-42a8-ab9a-e87697560209"},"source":["a = scale_bbox(cor[0], 0.5, 0.4)\r\n","cor[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([189, 64, 1078, 793], dtype=object)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gh4r95kfm6xw","executionInfo":{"status":"ok","timestamp":1609599836930,"user_tz":-480,"elapsed":670,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"4ebd5571-7500-4b6d-eb4e-835fa22b954f"},"source":["print(a)\r\n","print(tf.io.decode_raw(a.tobytes(), tf.float32))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0.41964287 0.11607143 2.40625    1.4151785 ]\n","tf.Tensor([0.41964287 0.11607143 2.40625    1.4151785 ], shape=(4,), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39-T0H3aS4f9","executionInfo":{"status":"ok","timestamp":1609602512842,"user_tz":-480,"elapsed":2611798,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"9b9be8b1-8c99-4e35-8acd-d0a1451f74e2"},"source":["cor = dataset_array[:, 1:].astype(int)\r\n","with tf.io.TFRecordWriter(os.path.join(csv_path, 'test_cor.tfrecord')) as writer:\r\n","  a, b = 0, 0\r\n","  for i in range(len(dataset_array)):\r\n","    img_name = dataset_array[i, 0]\r\n","    if os.path.isfile(image_path + img_name):\r\n","      w_image = plt.imread(os.path.join(image_path, img_name))\r\n","      x_scale, y_scale = (224 / w_image.shape[1]), (224 / w_image.shape[0])\r\n","      w_image = cv2.resize(w_image, (224, 224))\r\n","      new_box = scale_bbox(cor[i], x_scale, y_scale)\r\n","      new_box = new_box.tobytes()\r\n","      tf_example = image_example(w_image, new_box)\r\n","      writer.write(tf_example.SerializeToString())\r\n","      b += 1\r\n","    a += 1\r\n","writer.close()\r\n","print(a, b)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7363 7363\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8MzrWS0LItij"},"source":["#Read TF Dataset"]},{"cell_type":"code","metadata":{"id":"zOsgu-13k7fN"},"source":["BATCH_SIZE = 100\r\n","AUTOTUNE = tf.data.experimental.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WLN9cZvRtehr"},"source":["def decode_image(image):\n","    image = tf.image.decode_jpeg(image)\n","    image = tf.cast(image, tf.float32)\n","    image = image/255\n","    # image = tf.reshape(image, [224, 224, 3])\n","    return image\n","\n","def decode_label(label):\n","  label = tf.io.decode_raw(label, tf.float32)\n","  # label = p\n","  # label = tf.cast(label, tf.float32)\n","  return label\n","\n","def read_tfrecord(example, labeled):\n","    tfrecord_format = (\n","        {\n","            'image_raw': tf.io.FixedLenFeature([], tf.string),\n","            'target': tf.io.FixedLenFeature([], tf.string),\n","        }\n","        if labeled\n","        else {\"image_raw\": tf.io.FixedLenFeature([], tf.string)}\n","    )\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example['image_raw'])\n","    if labeled:\n","        label = decode_label(example['target'])\n","        # label = tf.cast(label, tf.int32)\n","        return image, label\n","    return image\n","\n","def load_dataset(filenames, labeled = False):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = True  # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(filenames)  # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(ignore_order)  \n","# uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(\n","        partial(read_tfrecord, labeled = labeled), num_parallel_calls = AUTOTUNE)\n","    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n","    return dataset\n","\n","def get_dataset(filenames, labeled = False):\n","    dataset = load_dataset(filenames, labeled = labeled)\n","#     dataset = dataset.shuffle(2048)\n","    dataset = dataset.prefetch(buffer_size = AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1c1TZfAUzUBz"},"source":["data = get_dataset(os.path.join(csv_path, 'test_cor.tfrecord'), labeled = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bSpYzvDbzmM3"},"source":["image_batch, label_batch = next(iter(data))"],"execution_count":null,"outputs":[]}]}